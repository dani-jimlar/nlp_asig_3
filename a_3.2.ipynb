{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, Tuple, TypeVar\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "import numpy as np\n",
    "\n",
    "Q = TypeVar(\"Q\")\n",
    "V = TypeVar(\"V\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')], [('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = nltk.corpus.brown.tagged_sents(tagset=\"universal\")[:10000]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')], [('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_corpus = nltk.corpus.brown.tagged_sents(tagset=\"universal\")[:10_000]\n",
    "tagged_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_corpus2 = nltk.corpus.brown.tagged_sents(tagset=\"universal\")[:5]\n",
    "tagged_corpus2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fun to count repeated elements in list\n",
    "def count_ngrams(lst):\n",
    "    element_count = {}\n",
    "    for item in lst:\n",
    "        if item in element_count:\n",
    "            element_count[item] += 1\n",
    "        else:\n",
    "            element_count[item] = 1\n",
    "    return element_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate list with all POS from corpus\n",
    "POS_list = []\n",
    "for i in tagged_corpus2:\n",
    "    POS_list += [tup[1] for tup in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dictioanary of counts of each POS\n",
    "POS_counts = count_ngrams(POS_list)\n",
    "# list of POS in corpus from dictionary POS_counts\n",
    "list_pos = list(POS_counts.keys())\n",
    "# list of POS counts from dictionary POS_counts\n",
    "list_counts_pos = list(POS_counts.values())\n",
    "# build list of probabilites out of counts\n",
    "ts = sum(list_counts_pos)\n",
    "pi = [c / ts for c in list_counts_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DET', 'NOUN', 'NOUN', 'ADJ', 'NOUN', 'VERB', 'NOUN', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADJ', 'NOUN', 'NOUN', 'VERB', '.', 'DET', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'VERB', 'NOUN', '.', 'DET', 'NOUN', 'ADV', 'VERB', 'ADP', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADJ', 'NOUN', '.', 'DET', 'VERB', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', '.', '.', 'VERB', 'DET', 'NOUN', 'CONJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'DET', 'NOUN', 'VERB', 'VERB', '.', 'DET', 'NOUN', 'NOUN', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'NOUN', 'ADJ', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'PRT', 'VERB', 'NOUN', 'ADP', 'ADJ', '.', 'NOUN', '.', 'ADP', 'DET', 'ADJ', 'NOUN', 'DET', 'VERB', 'VERB', 'ADP', 'NOUN', 'NOUN', 'NOUN', 'NOUN', '.', '.', 'ADV', 'DET', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', '.', 'DET', 'NOUN', 'VERB', '.', '.', 'ADP', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', '.', 'DET', 'NOUN', 'ADP', 'NOUN', 'CONJ', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', '.', '.', 'DET', 'NOUN', 'VERB', 'PRON', 'VERB', 'VERB', 'ADP', 'ADJ', 'ADP', 'NOUN', 'NOUN', 'CONJ', 'NOUN', 'NOUN', '.', 'VERB', 'ADJ', 'CONJ', 'ADJ', 'CONJ', 'ADV', 'ADJ', '.', '.']\n",
      "{'DET': 24, 'NOUN': 53, 'ADJ': 14, 'VERB': 21, 'ADP': 20, '.': 22, 'ADV': 3, 'CONJ': 5, 'PRT': 1, 'PRON': 1}\n",
      "orden pi: ['DET', 'NOUN', 'ADJ', 'VERB', 'ADP', '.', 'ADV', 'CONJ', 'PRT', 'PRON']\n",
      "[24, 53, 14, 21, 20, 22, 3, 5, 1, 1]\n",
      "[0.14634146341463414, 0.3231707317073171, 0.08536585365853659, 0.12804878048780488, 0.12195121951219512, 0.13414634146341464, 0.018292682926829267, 0.03048780487804878, 0.006097560975609756, 0.006097560975609756]\n",
      "suma de probs en pi: 1.0\n"
     ]
    }
   ],
   "source": [
    "# print pretty\n",
    "print(POS_list)\n",
    "print(POS_counts)\n",
    "print(\"orden pi:\", list_pos)\n",
    "print(list_counts_pos)\n",
    "print(pi)\n",
    "print(\"suma de probs en pi:\", sum(pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DET', 'NOUN', 'ADJ', 'VERB', 'ADP', '.', 'ADV', 'CONJ', 'PRT', 'PRON']\n",
      "[[ 1. 18.  3.  2.  0.  0.  0.  0.  0.  0.]\n",
      " [ 2. 13.  4.  8. 11. 10.  1.  3.  1.  0.]\n",
      " [ 0.  9.  0.  0.  1.  2.  0.  2.  0.  0.]\n",
      " [ 1.  3.  2.  6.  4.  4.  0.  0.  0.  1.]\n",
      " [10.  7.  3.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 7.  1.  0.  2.  4.  6.  1.  0.  0.  0.]\n",
      " [ 1.  0.  1.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  2.  1.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# matrix a\n",
    "\n",
    "## build dict of transition counts\n",
    "# function to build bigrams\n",
    "n_grams = [tuple(POS_list[i : i + 2]) for i in range(len(POS_list) - 1)]\n",
    "# function to count bigrams, stores tuple of bigram as keys and repetition count as value---\n",
    "d_pos_counts = count_ngrams(n_grams)\n",
    "d_pos_counts\n",
    "\n",
    "## build matrix\n",
    "# build cols for matrix according to order of pi\n",
    "unique_pos2 = list_pos\n",
    "# build empty matix with rows and cols using pos order from pi\n",
    "matrix_a = np.zeros((len(unique_pos2), len(unique_pos2)))\n",
    "# Populate the matrix with values from the dictionary\n",
    "for (pos1, pos2), count in d_pos_counts.items():\n",
    "    matrix_a[unique_pos2.index(pos1)][unique_pos2.index(pos2)] = count\n",
    "\n",
    "# Display the matrix\n",
    "print(unique_pos2)\n",
    "print(matrix_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build matrix B"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
